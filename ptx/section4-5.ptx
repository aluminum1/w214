

<section>
  <title>Kernel and range of a linear map</title>
  <definition>
    <statement>
      <p>
        Let <m>T : V \rightarrow W</m> be a linear map between vector spaces <m>V</m> and <m>W</m>.
        The <term>kernel</term> of <m>T</m>, written <m>\Ker(T)</m>,
        is the set of all vectors <m>\ve{v} \in V</m> such that are mapped to <m>\ve{0}_W</m> by <m>T</m>.
        That is,
        <me>
          \Ker(T) := \{ \ve{v} \in V : T(\ve{v}) = \ve{0}_W \}
        </me>.
      </p>

      <p>
        The <term>image</term> of <m>T</m>, written <m>\Im(T)</m>,
        is the set of all vectors <m>\ve{w} \in W</m> such that
        <m>\ve{w} = T(\ve{v})</m> for some <m>\ve{v} \in V</m>.
        That is,
        <me>
          \Im(T) := \{ \ve{w} \in W : \ve{w} = T(\ve{v}) \mbox{ for some \(\ve{v} \in V\)}  \}
        </me>
      </p>
    </statement>
  </definition>

  <p>
    See <xref ref="ker_and_im_fig">Figure</xref>
    for a schematic representation.
  </p>

  <assemblage>
    <p>
      Sometimes, to be absolutely clear, I will put a subscript on the zero vector to indicate which vector space it belongs to, eg.
      <m>\ve{0}_W</m> refers to the zero vector in <m>W</m>,
      while <m>\ve{0}_V</m> refers to the zero vector in <m>V</m>.
    </p>
  </assemblage>

  <assemblage>
    <p>
      Another name for the kernel of <m>T</m> is the
      <em>nullspace</em> of <m>T</m>,
      and another name for the image of <m>T</m> is the
      <em>range</em> of <m>T</m>.
    </p>
  </assemblage>

  <figure>
    <me>

      <image>

<latex-image>
          <![CDATA[\begin{tikzpicture}[scale=1.1]
 \draw (0,0) circle (1);
 \draw (0,0) circle (0.3);
 \draw (3,0) circle (1);
 \node at (0, -1.2) {\(V\)};
 \node at (3, -1.2) {\(W\)};
 \draw (0.083*0.6, 0.493*0.6) -- (3,0);
 \draw (0.083*0.6, -0.493*0.6) -- (3,0);
 \fill[fill=black] (3,0) circle (0.05);
 \node at (3.4, 0) {\(\ve{0}_W\)};
 \node at (0, -0.5) {\(\Ker(T)\)};\end{tikzpicture}]]>
</latex-image>
      </image>

    </me>
    \subcaption{Kernel of <m>T</m>}
    <me>

      <image>

<latex-image>
          <![CDATA[\begin{tikzpicture}[scale=1.1]
 \draw (0,0) circle (1);
 \draw (3,0) circle (0.3);
 \draw (3,0) circle (1);
 \node at (0, -1.2) {\(V\)};
 \node at (3, -1.2) {\(W\)};
 \draw (0.15, 0.987) -- (3.03,0.3);
 \draw (0.15, -0.987) -- (3.03,-0.3);
 \node at (3, -0.5) {\(\Im(T)\)};\end{tikzpicture}]]>
</latex-image>
      </image>

    </me>
    \subcaption{Image of <m>T</m>}
  </figure>

  <lemma xml:id="ker-im-subspace">
    <statement>
      <p>
        Let <m>T : V \rightarrow W</m> be a linear map.
        Then:

        <ul>
          <li>
            <title>(i)</title>
            <p>
              <m>\Ker(T)</m> is a subspace of <m>V</m>
            </p>
          </li>

          <li>
            <title>(ii)</title>
            <p>
              <m>\Im(T)</m> is a subspace of <m>W</m>
            </p>
          </li>
        </ul>
      </p>
    </statement>
  </lemma>

  <proof>
    <p>
      (i) We must check the three requirements for being a subspace.

      <ul>
        <li>
          <title>a.</title>
          <p>
            <m>\Ker(T)</m> is closed under addition.

            <blockquote>
              Suppose <m>\ve{v}</m> and <m>\ve{v}'</m> are in <m>\Ker(T)</m>. In other words, <m>T(\ve{v}) = \ve{0}</m> and <m>T(\ve{v}') = \ve{0}</m>. We need to show that <m>\ve{v} + \ve{v}'</m> is in <m>\Ker(T)</m>, in other words, that <m>T(\ve{v} + \ve{v}') = \ve{0}</m>. Indeed,
              <me>
                T(\ve{v} + \ve{v}') = T(\ve{v}) + T(\ve{v}') = \ve{0} + \ve{0} = \ve{0}
              </me>.
            </blockquote>

          </p>
        </li>

        <li>
          <title>b.</title>
          <p>
            <m>\ve{0}_V \in \Ker(T)</m>.

            <blockquote>
              To show that <m>\ve{0}_V</m> is in <m>\Ker(T)</m>, we need to show that <m>T(\ve{0}_V) = \ve{0}_W</m>. Indeed, this is true since <m>T</m> is a linear map, by <xref ref="lin_map_zero_to_zero">Lemma</xref>.
            </blockquote>

          </p>
        </li>

        <li>
          <title>c.</title>
          <p>
            <m>\Ker(T)</m> is closed under scalar multiplication.

            <blockquote>
              Suppose <m>\ve{v} \in \Ker(T)</m> and <m>k \in \mathbb{R}</m> is a scalar. We need to show that <m>k \ve{v} \in \Ker(T)</m>, that is, we need to show that <m>T(k \ve{v}) = \ve{0}</m>. Indeed,
              <me>
                T(k \ve{v}) = k T(\ve{v}) = k \ve{0} = \ve{0}
              </me>.
            </blockquote>

          </p>
        </li>
      </ul>
    </p>

    <p>
      (ii) Again, we must check the three requirements for being a subspace.

      <ul>
        <li>
          <title>a.</title>
          <p>
            <m>\Im(T)</m> is closed under addition.

            <blockquote>
              Suppose <m>\ve{w}</m> and <m>\ve{w}'</m> are in <m>\Im(T)</m>. In other words, there exist vectors <m>\ve{v}</m> and <m>\ve{v}'</m> in <m>V</m> such that <m>T(\ve{v}) = \ve{w}</m> and <m>T(\ve{v}') = \ve{w}'</m>. We need to show that <m>\ve{w} + \ve{w}'</m> is also in <m>\Im(T)</m>, in other words, that there exists a vector <m>\ve{u}</m> in <m>V</m> such that <m>T(\ve{u}) = \ve{w} + \ve{w}'</m>. Indeed, set <m>\ve{u} := \ve{v} + \ve{v}'</m>. Then,
              <me>
                T(\ve{u}) = T(\ve{v} + \ve{v}') = T(\ve{v}) + T(\ve{v}') = \ve{w} + \ve{w}'
              </me>.
            </blockquote>

          </p>
        </li>

        <li>
          <title>b.</title>
          <p>
            <m>\ve{0}_W \in \Im(T)</m>.

            <blockquote>
              To show that <m>\ve{0}_W \in \Im(T)</m>, we need to show that there exists <m>\ve{v} \in V</m> such that <m>T(\ve{v}) = \ve{0}_W</m>. Indeed, choose <m>\ve{v} = \ve{0}_V</m>. Then <m>T(\ve{v}) = T(\ve{0}_V) = \ve{0}_W</m> by <xref ref="lin_map_zero_to_zero">Lemma</xref>.
            </blockquote>

          </p>
        </li>

        <li>
          <title>c.</title>
          <p>
            <m>\Im(T)</m> is closed under scalar multiplication.

            <blockquote>
              Suppose <m>\ve{w} \in \Im(T)</m> and <m>k</m> is a scalar. We need to show that <m>k \ve{w} \in \Im(T)</m>. The fact that <m>\ve{w}</m> is in <m>\Im(T)</m> means that there exists a <m>\ve{v}</m> in <m>V</m> such that <m>T(\ve{v}) = \ve{w}</m>. We need to show that there exists a <m>\ve{u} \in V</m> such that <m>T(\ve{u}) = k \ve{w}</m>. Indeed, set <m>\ve{u} := k \ve{v}</m>. Then
              <me>
                T(\ve{u}) = T(k \ve{v}) = k T(\ve{v}) = k \ve{w}
              </me>.
            </blockquote>

          </p>
        </li>
      </ul>
    </p>
  </proof>

  <p>
    Now that we know that the kernel and image of a linear map are subspaces,
    and hence vector spaces in their own right,
    we can make the following definition.
  </p>

  <definition>
    <statement>
      <p>
        Let <m>T : V \rightarrow W</m> be a linear map from a finite-dimensional vector space <m>V</m> to a vector space <m>W</m>.
        The <term>nullity</term> of <m>T</m> is the dimension of <m>\Ker(T)</m>,
        and the <term>rank</term> of <m>T</m> is the dimension of <m>\Im(T)</m>:
        <md>
          <mrow>\Nullity(T) \amp := \Dim (\Ker(T))</mrow>
          <mrow>\Rank(T) \amp = \Dim (\Im(T))</mrow>
        </md>
      </p>
    </statement>
  </definition>

  <assemblage>
    <p>
      The <sq>dimension of <m>\Ker(T)</m></sq> makes sense because <m>\Ker(T)</m> is a subspace of a finite-dimensional vector space <m>V</m>,
      and hence is finite-dimensional by <xref ref="dim-of-subspace-prop">Proposition</xref>.
      We do not yet know that <m>\Im(T)</m> is finite-dimensional,
      but this will follow from the Rank-Nullity Theorem
      (<xref ref="rank-nullity-theorem">Theorem</xref>).
    </p>
  </assemblage>

  <example xml:id="cross-product-example">
    <statement>
      <p>
        Let <m>\ve{a} \in \mathbb{R}^3</m> be a fixed nonzero vector.
        Consider the <sq>cross product with <m>\ve{a}</m></sq> linear map from <xref ref="cross_prod_as_linear_map">Example</xref>,
        <md>
          <mrow>C : \mathbb{R}^3 \amp  \rightarrow \mathbb{R}^3</mrow>
          <mrow>\ve{v} \amp \mapsto \ve{a} \times \ve{v}</mrow>
        </md>
      </p>

      <p>
        Determine the kernel, image, nullity and rank of <m>C</m>.
      </p>
    </statement>
    <solution>
      <p>
        The kernel of <m>C</m> is the subspace of
        <m>\mathbb{R}^3</m> consisting of all vectors
        <m>\ve{v} \in V</m> such that <m>\ve{a} \times \ve{v} = \ve{0}</m>.
        From the geometric formula for the cross-product,
        <me>
          |\ve{a} \times \ve{v}| = |\ve{a}| |\ve{v}| \sin \theta
        </me>
        where <m>\theta</m> is the angle from <m>\ve{a}</m> to <m>\ve{\theta}</m>,
        we see that
        <me>
          \ve{a} \times \ve{v} = \ve{0}  \Leftrightarrow  \mbox{\(\ve{v}=\ve{0}\) or \(\theta = 0\) or \(\theta= \pi\)} 
        </me>.
      </p>

      <p>
        In other words,
        <m>\ve{v}</m> must be a scalar multiple of <m>\ve{a}</m>.
        So,
        <me>
          \Ker(C) = \{ k \ve{a}, k \in \mathbb{R} \}
        </me>.
      </p>

      <p>
        I claim that the <em>image</em>
        of <m>C</m> is the subspace of <em>all</em>
        vectors perpendicular to <m>\ve{a}</m>, i.e.
        <men xml:id="image-of-C">
          \Im(C) := \{ \ve{u} \in \mathbb{R}^3 : \ve{u} \cdot \ve{a} = 0 \}
        </men>.
      </p>

      <p>
        If you believe me, then the picture is as follows:
        <me>

          <image>

<latex-image>
          <![CDATA[\begin{tikzpicture}\draw (0,0) -- (1,2) -- (3,2) -- (2,0) -- (0,0);
  \draw (1.5, 1) -- (1.5,3.5) node[right] {\(\Ker{C}\)};
  \draw (1.5, -0.1) -- (1.5, -2);
  \node at (3.3, 1) {\(\Im(C)\)};  
  \draw[very thick, red, ->] (1.5,1) -- (1.5, 2.5) node[right] {\(\ve{a}\)};\end{tikzpicture}]]>
</latex-image>
          </image>

        </me>
      </p>

      <p>
        Let me prove equation <xref ref="image-of-C" />.
        By definition, the image of <m>C</m> is the subspace of
        <m>\mathbb{R}^3</m> consisting of all vectors <m>\ve{w}</m> of the form
        <m>\ve{w} = \ve{a} \times \ve{v}</m> for some <m>\ve{v} \in \mathbb{R}^3</m>.
        This implies that <m>\ve{w}</m> is perpendicular to <m>\ve{a}</m>.
        This was the <sq>easy</sq> part.
        The <sq>harder</sq> part is to show the converse.
        That is, we need to show that if <m>\ve{u}</m> is perpendicular to <m>\ve{a}</m>,
        then <m>\ve{u}</m> is in the image of <m>C</m>,
        i.e. there exists a vector <m>\ve{v}</m> such that <m>C(\ve{v}) = \ve{u}</m>.
      </p>

      <p>
        Indeed, we can choose <m>\ve{v}</m> to be the vector obtained by rotating <m>\ve{u}</m> by 90 degrees clockwise in the plane <m>I</m>,
        and scaling it appropriately:
        <me>

          <image>

<latex-image>
          <![CDATA[\begin{tikzpicture}\draw (0,0) -- (1,2) -- (3,2) -- (2,0) -- (0,0);
  \draw[very thick, red, ->] (1.5,1) -- (1.5, 2.5) node[right] {\(\ve{a}\)};
  \draw[very thick, blue, ->] (1.5,1) -- (1.75, 1.5) node[right, xshift=-6pt, yshift=3pt] {\(\ve{u}\)};
  \draw[very thick, green, ->] (1.5,1) -- (2, 1) node[xshift=-4pt, right] {\(\ve{v}\)};\end{tikzpicture}]]>
</latex-image>
          </image>

        </me>
      </p>

      <p>
        In terms of a formula, we have
        <me>
          \ve{v} = \frac{|\ve{u}|}{|\ve{a}|} \ve{u} \times \ve{a} 
        </me>.
      </p>

      <p>
        Note that this is not the <em>only</em>
        vector <m>\ve{v}</m> such that <m>C(\ve{v}) = \ve{u}</m>.
        Indeed, if we add to <m>\ve{v}</m> any vector that lies on the line through <m>\ve{a}</m>,
        the resulting vector
        <me>
          \tilde{\ve{v}} = \ve{v} + k \ve{a}
        </me>
      </p>

      <p>
        <em>also</em> satisfies <m>C(\tilde{\ve{v}}) = \ve{u}</m>, since
        <me>
          C(\tilde{\ve{v}}) = C(\ve{v} + k \ve{a}) = C(\ve{v}) + C(k \ve{a}) = \ve{u} + \ve{0} = \ve{u}
        </me>.
      </p>
    </solution>
  </example>

  <example>
    <statement>
      <p>
        Determine the kernel, image, nullity and rank of the linear map
        <md>
          <mrow>I : \Trig_2 \amp  \rightarrow \mathbb{R}</mrow>
          <mrow>f \amp  \mapsto \int_0^\pi f(x) dx </mrow>
        </md>.
      </p>
    </statement>
    <solution>
      <p>
        The kernel of <m>I</m> consists of all degree 2 trigonometric polynomials
        <me>
          f(x) = a_0 + a_1 \cos x + b_1 \sin x + a_2 \cos 2x + b_2 \sin 2x
        </me>
        such that
        <me>
          \int_0^\pi (a_0 + a_1 \cos x + b_1 \sin x + a_2 \cos 2x + b_2 \sin 2x) \, dx = 0
        </me>.
      </p>

      <p>
        Performing the integrals, this becomes the equation
        <me>
          \pi a_0 + 2 b_1 = 0
        </me>
        with no constraints on the other constants <m>a_1, a_2, b_2</m>.
        In other words,
        <me>
          \Ker(I) = \left\{ \mbox{ all trigonometric polynomials of the form  \\ \(a_0(1 - \frac{\pi}{2} \sin x) + a_1 \cos x + a_2 \cos{2x} + b_2 \sin{2x}\), \\ where \(a_0, a_1, a_2, b_2 \in \mathbb{R}\). }  \right\}
        </me>
      </p>

      <p>
        Hence <m>\Nullity(I) = \Dim (\Ker(I)) = 4</m>.
      </p>

      <p>
        The image of <m>I</m> consists of all real numbers
        <m>p \in \mathbb{R}</m> such that there exists a
        <m>f \in \Trig_2</m> such that <m>I(f) = p</m>.
        I claim that
        <me>
          \Im(I) = \mathbb{R}
        </me>.
      </p>

      <p>
        Indeed, given <m>p \in \mathbb{R}</m>,
        we may choose <m>f(x) = \frac{p}{2} \sin{x}</m>, since
        <me>
          I(f) = \frac{p}{2} \int_0^\pi \sin{x} \, dx  = p
        </me>.
      </p>

      <p>
        Hence <m>\Im(I) = \mathbb{R}</m>, and <m>\Rank(I) = 1</m>.
      </p>

      <p>
        Note that the choice of <m>f(x) = \frac{p}{2} \sin(x)</m> satisfying <m>I(f) = p</m> is not unique.
        We could set <m>\tilde{f} = f + g</m> where
        <m>g \in \Ker(I)</m> and we would still have <m>I(\tilde{f})=p</m>:
        <me>
          I(\tilde{f}) = I(f + g) = I(f) + I(g) =  p + 0 = p
        </me>.
      </p>
    </solution>
  </example>

  <example>
    <statement>
      <p>
        Consider the function
        <md>
          <mrow>T : \Poly_2 \amp  \rightarrow \mathbb{R}^2</mrow>
          <mrow>p \amp  \mapsto (p(1), p'(1))</mrow>
        </md>.
      </p>

      <p>
        Show that <m>T</m> is a linear map,
        and determine its kernel, image, rank and nullity.
      </p>
    </statement>
    <solution>
      <p>
        We first show that <m>T</m> is a linear map.
        Let <m>p,q \in \Poly_2</m>.
        Then
        <md>
          <mrow>T(p + q) \amp = ( (p+q)(1), \, (p+q)'(1) )  \amp \amp  \mbox{(Defn of \(T\))}</mrow>
          <mrow>\amp = (p(1) + q(1), \, (p+q)'(1) ) \amp \amp  \mbox{(Defn of the function \(p+q\))}</mrow>
          <mrow>\amp = (p(1) + q(1), \, (p'+q')(1) ) \amp \amp  \mbox{(\((p+q)' = p'+q'\))}</mrow>
          <mrow>\amp = (p(1) + q(1), \, p'(1) + q'(1)) \amp \amp  \mbox{(Defn of the function \(p' + q'\))}</mrow>
          <mrow>\amp = (p(1), \, p'(1)) + (q(1), \, q'(1)) \amp \amp  \mbox{(Defn of addition in \(\mathbb{R}^2\))}</mrow>
          <mrow>\amp = T(p) + T(q)</mrow>
        </md>.
      </p>

      <p>
        The proof of <m>T(kp) = kT(p)</m> is similar.
      </p>

      <p>
        The kernel of <m>T</m> is the set of all polynomials
        <me>
          p(x) = a_0 + a_1 x + a_2 x^2
        </me>
        such that <m>T(p) = (0,0)</m>.
        This translates into the equation
        <me>
          (a_0 + a_1 + a_2, \, a_1 + 2 a_2) = (0,0)
        </me>.
      </p>

      <p>
        This in turn translates into two equations:
        <me>
          \systeme{ a_0 + a_1 + a_2 = 0, a_1 + 2a_2 = 0}
        </me>
        whose solution is <m>a_2 = t</m>,
        <m>a_1 = - 2t</m>, <m>a_0 = -t</m>,
        where <m>t \in \mathbb{R}</m>.
        Hence
        <me>
          \Ker(T) =  \left\{ \mbox{ all polynomials of the form  \\ \( -t -2t x + t x^2\)  where  \(t \in \mathbb{R}\) }  \right\}
        </me>.
      </p>

      <p>
        Hence <m>\Nullity(T) = 1</m>.
      </p>

      <p>
        The image of <m>T</m> is the set of all
        <m>(v,w) \in \mathbb{R}^2</m> such that there exists a polynomial
        <m>p = a_0 + a_1 x + a_2 x^2</m> in <m>\Poly_2</m> such that <m>T(p) = (v,w)</m>.
        So, <m>(v,w)</m> is in the image of <m>T</m> if and only if we can find a polynomial <m>p = a_0 + a_1x + a_2 x^2</m> such that
        <me>
          (a_0 + a_1 + a_2, a_1 + 2a_2) = (v,w)
        </me>.
      </p>

      <p>
        In other words,
        <m>(v,w)</m> is in the image of <m>T</m> if and only if the equations
        <me>
          \systeme{ a_0 + a_1 + a_2 = v, a_1 + 2a_2 = w}
        </me>
        have a solution for some <m>a_0, a_1, a_2</m>.
        But these equations <em>always</em> have a solution,
        for <em>all</em> <m>(v,w) \in \mathbb{R}^2</m> is.
        For instance, one solution is
        <me>
          a_2 = 0 ,  \, a_1 = w, \, a_0 = v - w
        </me>
        which corresponds to the polynomial
        <men xml:id="one-soln-for-preimage">
          p(x) = v-w + wx
        </men>.
      </p>

      <p>
        Note that indeed <m>T(p) = (v,w)</m>.
        Hence,
        <me>
          \Im(T) = \{\mbox{all }  (v,w) \in \mathbb{R}^2 \} = \mathbb{R}^2
        </me>.
      </p>

      <p>
        Hence <m>\Rank (T) = \Dim (\Im(T)) = 2</m>.
      </p>

      <p>
        Note that the choice of the polynomial
        <m>p(x) = v-w + w x</m> from <xref ref="one-soln-for-preimage" /> which satisfies <m>T(p) = (v,w)</m> is not the
        <em>only</em> possible choice.
        Indeed, any polynomial of the form <m>\tilde{p} = p + q</m> where
        <m>q \in \Ker(T)</m> will also satisfy <m>T(\tilde{p}) = (v,w)</m>, since
        <me>
          T(\tilde{p}) = T(p + q) = T(p) + T(q) = (v,w) + (0,0) = (v,w)
        </me>.
      </p>
    </solution>
  </example>

  <theorem xml:id="rank-nullity-theorem">
    <title>Rank-nullity theorem</title>
    <statement>
      <p>
        Let <m>T : V \rightarrow W</m> be a linear map from a finite-dimensional vector space <m>V</m> to a vector space <m>W</m>.
        Then
        <me>
          \Nullity(T) + \Rank(T) = \Dim(V)
        </me>.
      </p>
    </statement>
  </theorem>

  <proof>
    <p>
      Let <m>\basis{B} = \bopen \ve{e}_1, \ldots, \ve{e}_k \bclose</m> be a basis for <m>\Ker(T)</m>.
      Since <m>\basis{B}</m> is a list of linearly independent vectors in <m>V</m>,
      we can extend it to a basis <m>\basis{C} = \bopen \ve{e}_1, \ldots, \ve{e}_k, \ve{f}_1, \ldots, \ve{f}_p \bclose</m> for <m>V</m>,
      by <xref ref="first_corollary_please">Corollary</xref>.
      I claim that
      <me>
        \basis{D} := \bopen T(\ve{f}_1), \ldots, T(\ve{f}_p) \bclose
      </me>
      is a basis for <m>\Im(T)</m>.
      If I can prove that, then we are done, since then we have
      <md>
        <mrow>\Nullity(T) + \Rank(T) \amp = k + p</mrow>
        <mrow>\amp = \Dim(V)</mrow>
      </md>.
    </p>

    <p>
      Let us prove that <m>\basis{D}</m> is a basis for <m>\Im(T)</m>.
    </p>

    <p>
      <em><m>\basis{D}</m> is linearly independent</em>.
      Suppose
      <me>
        b_1 T(\ve{f}_1) + \cdots + b_p T(\ve{f}_p) = \ve{0}_W
      </me>.
    </p>

    <p>
      We recognize the left hand side as <m>T(b_1 \ve{f}_1 + \cdots + b_p \ve{f}_p)</m>.
      Hence
      <me>
        b_1 \ve{f}_1 + \cdots + b_p \ve{f}_p \in \Ker(T)
      </me>
      which means we can write it as a linear combination of the vectors in <m>\basis{B}</m>,
      <me>
        b_1 \ve{f}_1 + \cdots + b_p \ve{f}_p = a_1 \ve{e}_1 + \cdots + a_k \ve{e}_k
      </me>.
    </p>

    <p>
      Bringing all terms onto one side, this becomes the equation
      <me>
        -a_1 \ve{e}_1 - \cdots -a_k \ve{e}_k + b_1 \ve{f}_1 + \cdots + b_p \ve{f}_p = \ve{0}_V
      </me>.
    </p>

    <p>
      We recognize the left hand side as a linear combination of the <m>\basis{C}</m> basis vectors.
      Since they are are linearly independent,
      all the scalars must be zero.
      In particular, <m>b_1 = \cdots = b_p = 0</m>,
      which is what we wanted to prove.
    </p>

    <p>
      <em><m>\basis{D}</m> spans <m>W</m></em>.
      Suppose <m>\ve{w} \in \Im(T)</m>.
      We need to show that <m>\ve{w}</m> is a linear combination of the vectors from <m>\basis{D}</m>.
      Since <m>\ve{w}</m> is in the image of <m>T</m>,
      there exists <m>\ve{v} \in V</m> such that <m>T(\ve{v}) = \ve{w}</m>.
      Since <m>\basis{C}</m> is a basis for <m>V</m>, we can write
      <me>
        \ve{v} = a_1 \ve{e}_1 + \cdots + a_k \ve{e}_k + b_1 \ve{f}_1 + \cdots + b_p \ve{f}_p
      </me>
      for some scalars <m>a_1, \ldots,
      a_k, b_1, \ldots, b_p</m>.
      Then
      <md>
        <mrow>\ve{w} \amp =   T(\ve{v})</mrow>
        <mrow>\amp = T(a_1 \ve{e}_1 + \cdots + a_k \ve{e}_k + b_1 \ve{f}_1 + \cdots + b_p \ve{f}_p)</mrow>
        <mrow>\amp = a_1 T(\ve{e}_1) + \cdots + a_k T(\ve{e}_k) + b_1 T(\ve{f}_1) + \cdots + b_p T(\ve{f}_p)</mrow>
        <mrow>\amp = b_1 T(\ve{f}_1) + \cdots + b_p T(\ve{f}_p) \amp \amp  \mbox{(\(\ve{e}_i \in \Ker(T)\))}</mrow>
      </md>
      so that <m>\ve{w}</m> is indeed a linear combination of the vectors from <m>\basis{D}</m>.
    </p>
  </proof>
</section>

