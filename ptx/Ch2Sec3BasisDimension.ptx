

<section xml:id="Ch2Sec3BasisDimension">
  <title>Basis and dimension</title>
  <introduction>
    <definition>
      <statement>
        <p>
          A list of vectors <m>\basis{B} = \left\{ \ve{e}_1,
          \ve{e}_2,\ldots,
         \ve{e}_n\right\}</m> in a vector space <m>V</m> is called a <term>basis</term>
          for <m>V</m> if it is linearly independent and spans <m>V</m>.
        </p>
      </statement>
    </definition>

    <theorem xml:id="inv_dim">
      <title>Invariance of dimension</title>
      <statement>
        <p>
          If <m>\basis{B} = \left\{ \ve{b}_1, \ve{b}_2, \ldots, \ve{b}_m \right\}</m> and
          <m>\basis{C} = \left\{ \ve{c}_1, \ve{c}_2, \ldots, \ve{c}_n\right\}</m> are bases of a vector space <m>V</m>,
          then <m>m=n</m>.
        </p>
      </statement>
    </theorem>

    <proof>
      <p>
        This is a consequence of <xref ref="bumping_off_lemma">Proposition</xref>
        (the Bumping Off Proposition).
        Since the <m>\ve{b}</m>-vectors are linearly independent and the <m>\ve{c}</m>-vectors span <m>V</m>,
        we have <m>m \leq n</m>.
        On the other hand,
        since the <m>\ve{c}</m>-vectors are linearly independent and the <m>\ve{b}</m>-vectors span <m>V</m>,
        we have <m>n \leq m</m>.
        Hence <m>m=n</m>.
      </p>
    </proof>

    <definition>
      <statement>
        <p>
          A vector space <m>V</m> is <term>finite-dimensional</term> if it has a basis.
          In that case, the <term>dimension</term>
          of <m>V</m> is the number of elements in a basis for <m>V</m>.
          A vector space is <term>infinte-dimensional</term>
          if it is not finite-dimensional.
        </p>
      </statement>
    </definition>

    <assemblage>
      <p>
        Note that the concept of <sq>dimension of a vector space</sq> is only well-defined because of <xref ref="inv_dim">Theorem</xref>.
      </p>
    </assemblage>

    <example xml:id="standard_basis_R_n_ex">
      <title>Standard basis for <m>\mathbb{R}^n</m></title>
      <statement>
        <p>
          The list of vectors
          <me>
            \ve{e}_1 := (1, 0, \ldots, 0), \,\,\, \ve{e}_2 := (0, 1, \ldots, 0), \,\,\, \ldots, \,\,\, \ve{e}_n := (0, 0, \ldots, 0, 1)
          </me>
          is a basis for <m>\mathbb{R}^n</m>.
          We already saw in <xref ref="Rn_spanning_set">Example</xref>
          that this list spans <m>\mathbb{R}^n</m>.
          We need to check that it is linearly independent.
          So, suppose that
          <me>
            a_1 \ve{e}_1 + a_2 \ve{e}_2 + \cdots + a_n \ve{e}_n = \ve{0}
          </me>.
        </p>

        <p>
          Expanding out the left hand side in components using the definition of the standard basis vectors
          <m>\ve{e}_i</m>, this becomes the equation
          <me>
            (a_1, 0, 0, \ldots, 0) + (0, a_2, 0, \ldots, 0) + \cdots + (0, 0, 0,
            \ldots, a_n) = (0, 0, 0, \ldots, 0)
          </me>.
        </p>

        <p>
          In other words, we have
          <me>
            (a_1, a_2, a_3, \ldots, a_n) = (0, 0, 0, \ldots, 0)
          </me>
          which says precisely that <m>a_1 = a_2 = a_3 = \cdots = a_n = 0</m>,
          which is what we needed to prove.
          Thus the list of vectors <m>\ve{e}_1, \ve{e}_2, \ldots, \ve{e}_n</m> is linearly independent,
          and is hence a basis for <m>\mathbb{R}^n</m>.
          So <m>\mathbb{R}^n</m> has dimension <m>n</m>.
        </p>
      </statement>
    </example>

    <example>
      <title>A basis for <m>\mathbb{R}^4</m></title>
      <statement> <p> Check whether the following list of vectors
        <men>
       \ve{v}_1 = (1, 0, 2, -3), \, \ve{v}_2 = (1, 3, -1, 2), \, \ve{v}_3 = (0, 1, 2, -1), \ve{v}_4 = (1, 2, 3, 4)
      </men>
      is a basis for <m>\mathbb{R}^4</m>. </p></statement>

      <solution> 
        <p>
          First we check if the list of vectors is <xref ref="defn_of_linear_ind" text="title">linearly independent</xref>. Consider the equation
          <mdn>
            <mrow> a_1 \ve{v}_1 + a_2 \ve{v}_2 + a_3 \ve{v}_3 + a_4 \ve{v}_4 \amp = \ve{0} </mrow>
            <mrow> \therefore a_1 (1, 0, 2,-3) + a_2 (1, 3, -1, 2) + a_3 (0, 1, 2, -1) + a_4 (1, 2, 3, 4) \amp = (0, 0, 0, 0) </mrow>
            <mrow> \therefore (a_1 - a_2 + a_4, 3a_2 + a_3 + 2a_4, 2a_1 - a_2 + 2a_3 + 3a_4, -3a_1 + 2a_2 -a_3 + 4a_4) \amp = (0,0,0,0) </mrow>
        </mdn>
        So the list of vectors is linearly indepedent if and only if the following equations have only the trivial solution <m>a_1 = 0, a_2 = 0, a_3 = 0, a_4 = 0</m>:
        <mdn>
    <mrow xml:id="R4-example-eqn1"> a_1 - a_2 + a_4 \amp = 0 </mrow>
    <mrow> 3a_1 + a_3 + 2a_4 \amp = 0 </mrow>
    <mrow> 2a_1 - a_2 + 2a_3 + 3a_4 \amp = 0 </mrow>
    <mrow xml:id="R4-example-eqn4"> -3a_1 + 2a_2 - a_3 + 4a_4 \amp = 0 </mrow>
        </mdn>
        We can compute the solutions to equations <xref first="R4-example-eqn1" last="R4-example-eqn4"/>  by hand, or using SageMath.
        </p> 
        <sage>
          <input>
            var('a1, a2, a3, a4')

            solve([a1 - a2 + a4 == 0,
                  3*a1 + a3 + 2*a4 == 0,
                  2*a1 - a2 + 2*a3 + 3*a4 == 0,
                  -3*a1 + 2*a2 - a3 + 4*a4 == 0],
                  [a1, a2, a3, a4])
          </input>
        </sage>    
      <p> SageMath outputs:
      <sidebyside>
       <p> <c> [[a1 == 0, a2 == 0, a3 == 0, a4 == 0]] </c></p>
      </sidebyside>     
      So indeed,  equations <xref first="R4-example-eqn1" last="R4-example-eqn4"/>  have only the trivial solution. Therefore the list of vectors is linearly independent. </p>

      <p> Next, we need to check that the list of vectors spans <m>\mathbb{R}^4</m>. (There is a shorter way of doing this, using <xref ref="lin-ind-implies-basis"/> below, but for now we prove it from first principles.) So, let <m>\ve{w} = (w_1, w_2, w_3, w_4)</m> be an arbitrary vector in <m>\mathbb{R}^4</m>. We need to show that there exists at least one way to express <m>\ve{w}</m> as a linear combination of the vectors <m>\ve{v}_1, \ve{v}_2, \ve{v}_3, \ve{v}_4</m>. In other words, we need to check if there exists at least one solution to the following equation:
         <mdn>
            <mrow xml:id="fund_eqn_span_r4_ex"> a_1 \ve{v}_1 + a_2 \ve{v}_2 + a_3 \ve{v}_3 + a_4 \ve{v}_4 \amp = \ve{w} </mrow>
            <mrow> \therefore a_1 (1, 0, 2,-3) + a_2 (1, 3, -1, 2) + a_3 (0, 1, 2, -1) + a_4 (1, 2, 3, 4) \amp = (w_1, w_2, w_3, w_4) </mrow>
            <mrow> \therefore (a_1 - a_2 + a_4, 3a_2 + a_3 + 2a_4, 2a_1 - a_2 + 2a_3 + 3a_4, -3a_1 + 2a_2 -a_3 + 4a_4) \amp = (w_1, w_2, w_3, w_4) </mrow>
        </mdn>
        So the list of vectors spans <m>\mathbb{R}^4</m> if and only if the following equations for <m>a_1, a_2, a_3, a_4</m> always have a solution, no matter what the values of <m>w_1, w_2, w_3, w_4</m> are:
           <mdn>
    <mrow xml:id="R4-example-span-eqn1"> a_1 - a_2 + a_4 \amp = w_1 </mrow>
    <mrow> 3a_1 + a_3 + 2a_4 \amp = w_2 </mrow>
    <mrow> 2a_1 - a_2 + 2a_3 + 3a_4 \amp = w_3 </mrow>
    <mrow xml:id="R4-example-span-eqn4"> -3a_1 + 2a_2 - a_3 + 4a_4 \amp = w_4 </mrow>
        </mdn>
        We can compute the solutions to equations <xref first="R4-example-span-eqn1" last="R4-example-span-eqn4"/>  by hand, or using SageMath:</p>
        <sage>
          <input>
            var('a1, a2, a3, a4, w1, w2, w3, w4')

            solve([a1 - a2 + a4 == w1,
                  3*a1 + a3 + 2*a4 == w2,
                  2*a1 - a2 + 2*a3 + 3*a4 == w3,
                  -3*a1 + 2*a2 - a3 + 4*a4 == w4],
                  [a1, a2, a3, a4])
          </input>
        </sage>    
        <p>Note that we ask SageMath to solve for <c>a1, a2, a3, a4</c>, since <c>w1, w2, w3, w4</c> are regarded as constants in the equation... we are not trying to solve for them, they are fixed, but arbitrary! SageMath outputs:</p>
        <sidebyside>
          <p>
            <c> [[a1 == 1/9*w1 + 7/18*w2 - 2/9*w3 - 1/18*w4, a2 == -2/3*w1 + 5/12*w2 - 1/6*w3 + 1/12*w4, a3 == -7/9*w1 - 2/9*w2 + 5/9*w3 - 1/9*w4, a4 == 2/9*w1 + 1/36*w2 + 1/18*w3 + 5/36*w4]] </c>
          </p>
        </sidebyside>
        <p>In other words, there does indeed exist a solution, no matter what <m>(w_1, w_2, w_3, w_4)</m> is. For instance, if <m>(w_1, w_2, w_3, w_4) = (3, 1, 2, 4) </m>, then the solution is
        <me>
           a_1 = \frac{1}{18}, a_2 = - \frac{19}{12}, a_3 = -\frac{17}{9}, a_4 = \frac{49}{36}.
      </me>
        In other words, 
        <me>
          (3, 1, 2, 4) = \frac{1}{18} \ve{v}_1 - \frac{19}{12} \ve{v}_2 - \frac{17}{9} \ve{v}_3 + \frac{49}{36} \ve{v}_4.
      </me>
      Since there exists a solution to equation <xref ref="fund_eqn_span_r4_ex"/> for each vector <m>\ve{w} \in \mathbb{R}^4</m>, we conclude that <m>\bopen \ve{v}_1, \ve{v}_2, \ve{v}_3, \ve{v}_4 \bclose</m> spans <m>\mathbb{R}^4</m>. </p>

      <p>Hence <m>\bopen \ve{v}_1, \ve{v}_2, \ve{v}_3, \ve{v}_4 \bclose</m>  is a basis for <m>\mathbb{R}^4</m>, since it is linearly independent and spans <m>\mathbb{R}^4</m>.</p>
      </solution>

    </example>

    <example>
      <statement>
        <p>
          The list of polynomials
          <me>
            \ve{p}_0 (x) := 1, \, \ve{p}_1 (x) := x, \, \ve{p}_2 (x) := x^2, \, \ldots, \, \ve{p}_n (x) := x^n
          </me>
          is a basis for <m>\Poly_n</m>,
          so <m>\Dim \Poly_n = n+1</m>.
          Indeed, this list spans <m>\Poly_n</m> by definition,
          so we just need to check that it is linearly independent.
          Suppose that
          <me>
            a_0 \ve{p}_0 + a_1 \ve{p}_1 + a_2 \ve{p_2} + \cdots + a_n \ve{p}_n = \ve{0}
          </me>.
        </p>

        <p>
          <em>This is an equation between functions,
          so it holds for all <m>x \in \mathbb{R}</m>!</em> In other words,
          for all <m>x \in \mathbb{R}</m>,
          the following equation holds:
          <men xml:id="root_of_poly">
            a_0 + a_1 x + a_2 x^2 + \cdots + a_n x^n = 0
          </men>
        </p>

        <p>
          But, we know from algebra that a polynomial equation of the form <xref ref="root_of_poly" /> with nonzero coefficients has <em>at most</em>
          <m>n</m> roots <m>x_1, x_2, \ldots, x_n</m>.
          So, in order for <xref ref="root_of_poly" /> to hold for
          <em>all</em> real numbers <m>x</m>,
          the coefficients must be zero, i.e.
          <m>a_0 = a_1 = a_2 = \cdots = a_n = 0</m>,
          which is what we needed to show.
        </p>
      </statement>
    </example>

    <example>
      <statement>
      <p>
        Suppose <m>X</m> is a finite set.
        Then <m>\Fun(X)</m> is finite-dimensional,
        with dimension <m>|X|</m>,
        with basis given by the functions <m>\ve{f}_a</m>,
        <m>a \in X</m>, defined by:
        <men xml:id="defn_of_basis_of_functions">
          \ve{f}_a (x) :=  \begin{cases} 1 \amp  \mbox{ if }  x = a \\ 0 \amp  \mbox{ otherwise}  \end{cases}
        </men>
      </p>

      <p>
        We will prove this in a series of exercises.
      </p>

      <assemblage>
        <p>
          The formula on the right hand side of <xref ref="defn_of_basis_of_functions" /> occurs so often in mathematics we give it a symbol of its own,
          <m>\delta_{ab}</m>
          (the <sq>Kronecker delta</sq>).
          This symbol stands for the formula:
          <q>If <m>a=b</m>, return a 1.
          If <m>a \neq b</m>, return a <m>0</m></q>.
          In this language,
          we can rewrite the definition of the functions <m>\ve{f}_a</m> as
          <men>
            \ve{f}_a (x) := \delta_{ax}
          </men>.
        </p>
      </assemblage>
      </statement>
    </example>

    <!--ERROR FIX THIS HIEROGLYPHIC STUFF AND THE NEXT EXERCISE TOO

    <exercise>
        <statement>
          <p>
            Suppose <m>X = \left\{\mbox{\pmglyph{\HGi}} , \mbox{\pmglyph{\He}} , \mbox{\pmglyph{\HZxi}} \right\}</m>.

            <ol>
              <li>
                <p>
                  Evaluate the function <m>\ve{f}_{\mbox{\tiny \pmglyph{\HGi}} }</m> at each <m>x \in X</m>.
                </p>
              </li>

              <li>
                <p>
                  Show that every function <m>\ve{f} \in \Fun(X)</m> can be written as a linear combination of <m>\ve{f}_{\mbox{\tiny \pmglyph{\HGi}} }</m>,
                  <m>\ve{f}_{\mbox{\tiny \pmglyph{\He}} }</m> and <m>\ve{f}_{\mbox{\tiny \pmglyph{\HZxi}} }</m>.
                </p>
              </li>
            </ol>
          </p>
        </statement>
      </exercise>

      

      <exercise>
        <statement>
          <p>
            Now let <m>X</m> be an arbitrary finite set.
            Consider the collection of functions
            <me>
              \ve{f}_a, \, a \in X
            </me>
          </p>
          <p>
            Show that this collection (i) spans <m>\Fun(X)</m> and (ii) is linearly independent.
          </p>
        </statement>
      </exercise>

      -->

    <example>
      <statement>
        <p>
          <m>\Trig_n</m> is <m>(2n+1)</m>-dimensional, with basis
          <md>
            <mrow>\ve{T}_0 (x) := 1, \,\,\, \ve{T}_1 (x) := \cos x, \,  \ve{T}_2 (x) := \sin x, \, \ve{T}_3 (x) := \cos 2x, </mrow>
            <mrow> \ve{T}_4 (x) := \sin 2x, \, \ldots, \, \ve{T}_{2n-1} (x) := \cos nx , \, \ve{T}_{2n} (x) := \sin nx.</mrow>
          </md>
        </p>

        <p>
          You know that these functions span <m>\Trig_n</m>, by definition.
          They are also linearly independent,
          though we will not prove this.
        </p>
      </statement>
    </example>

    <example xml:id="dimension_of_matrix_space_example">
      <statement>
      <p>
        The dimension of <m>\Mat_{n,m}</m> is <m>nm</m>,
        with basis given by the matrices
        <me>
          \mat{E}_{ij} ,  i=1 \ldots n, \, j = 1 \ldots m
        </me>
        which have a <m>1</m> in the <m>i</m>th row and <m>j</m>th column and zeroes everywhere else.
      </p>

      <assemblage>
        <p>
          Usually <m>\mat{A}</m> is a matrix,
          and <m>\mat{A}_{ij}</m> is the element of the matrix at position <m>(i,j)</m>.
          But now <m>\mat{E}_{ij}</m> is a matrix in its own right!
          Its element at position <m>(k,l)</m> will be written as <m>(\mat{E}_{ij})_{kl}</m>.
          I hope you don't find this too confusing.
          In fact, we can write down an elegant formula for the elements of
          <m>\mat{E}_{ij}</m> using the Kronecker delta symbol:
          <men xml:id="kronecker_for_matrix_basis">
            (\mat{E}_{ij})_{kl} = \delta_{ik} \delta_{jl}
          </men>
        </p>
      </assemblage>
      </statement>
    </example>

    <exercise>
        <statement>
          <p>
            Check that <xref ref="kronecker_for_matrix_basis" /> is indeed the correct formula for the matrix elements of <m>\mat{E}_{ij}</m>.
          </p>
        </statement>
      </exercise>

    <example>
      <statement>
        <p>
          The standard basis of <m>\Mat_{2,2}</m> is
          <me>
            \mat{E}_{11} = \left[ \begin{array}{cc} 1 \amp  0 \\ 0 \amp  0
            \end{array}  \right], \, \mat{E}_{12} = \left[ \begin{array}{cc} 0 \amp  1 \\ 0 \amp  0
            \end{array}  \right], \mat{E}_{21} = \left[ \begin{array}{cc} 0 \amp  0 \\ 1 \amp  0
            \end{array}  \right], \mat{E}_{22} = \left[ \begin{array}{cc} 0 \amp  0 \\ 0 \amp  1
            \end{array}  \right]
          </me>.
        </p>
      </statement>
    </example>

    <example>
      <statement>
        <p>
          The standard basis of <m>\Col_n</m> is
          <me>
            \col{e}_1 := \left[ \begin{array}{c} 1 \\ 0 \\ \vdots \\ 0
            \end{array}  \right], \, 
            \col{e}_2 := \left[ \begin{array}{c} 0 \\ 1 \\ \vdots \\ 0
            \end{array}  \right], \, 
            \ldots, \,
            \col{e}_n := \left[ \begin{array}{c} 0 \\ 0 \\ \vdots \\ 1
            \end{array}  \right] 
          </me>.
        </p>
      </statement>
    </example>

    <p>
      We now consider dimensions of subspaces of vector spaces.
    </p>

    <proposition xml:id="dim-of-subspace-prop">
      <statement>
        <p>
          Let <m>W</m> be a subspace of a finite-dimensional vector space <m>V</m>.
          Then <m>W</m> is finite-dimensional,
          and <m>\Dim(W) \leq \Dim(V)</m>.
        </p>
      </statement>
    </proposition>

    <proof>
      <p>
        Let <m>n = \Dim(V)</m>.
        If <m>W = \{ \ve{0} \}</m>, then the statement is clearly true.
        Suppose <m>W \neq \{ \ve{0} \}</m>.
        Choose a nonzero vector <m>\ve{e}_1 \in W</m> and form the list <m>\basis{B}_1 = \left\{ \ve{e}_1 \right\}</m>.
        If it spans <m>W</m>, then we are done.
        If not, there exists <m>\ve{e}_2 \in W</m> which is not a scalar multiple of <m>\ve{e}_1</m>.
        Now consider the list <m>\basis{B}_2 = \left\{ \ve{e}_1, \ve{e}_2 \right\}</m>.
        If it spans <m>W</m>, we are done.
        If not, there exists a vector
        <m>\ve{e}_3 \in W</m> which is not a linear combination of <m>\ve{e}_1</m> and <m>\ve{e}_2</m>.
        Consider the new list <m>\basis{B}_3 = \left\{ \ve{e}_1, \ve{e}_2, \ve{e}_3 \right\}</m>.
        And so on.
      </p>

      <p>
        This process must eventually terminate.
        That is, there must exist some
        <m>k \geq 1</m> such that <m>\basis{B}_k = \left\{ \ve{e}_1, \ldots, \ve{e}_k \right\}</m> spans <m>W</m>,
        and hence is a basis for <m>W</m>.
        This is because each list <m>\basis{B}_i</m> is linearly independent
        (by construction,
        no vector is a linear combination of the preceding vectors).
        And it is impossible to construct a linearly independent list of vectors in <m>W</m>
        (and hence in <m>V</m>)
        which has more than <m>n</m> elements,
        by the Bumping Off Proposition.
        This also shows that <m>k \leq n</m>.
      </p>
    </proof>

    <p>
      It is good to have an example of an infinite-dimensional vector space.
    </p>

    <proposition>
      <statement>
        <p>
          <m>\Poly</m> is infinite-dimensional.
        </p>
      </statement>
    </proposition>

    <proof>
      <p>
        Suppose <m>\Poly</m> is finite-dimensional.
        This means there exists a finite collection of polynomials
        <m>\ve{p}_1, \ve{p}_2, \ldots, \ve{p}_n</m> which spans <m>\Poly</m>.
        But, let <m>d</m> be the highest degree of all the polynomials in the list <m>\ve{p}_1, \ve{p}_2, \ldots, \ve{p}_n</m>.
        Then <m>\ve{p} := x^{d+1}</m> is a polynomial which is not in the span of <m>\ve{p}_1, \ve{p}_2, \ldots, \ve{p}_n</m>,
        since adding polynomials together and multiplying them by scalars can never increase the degree.
        We have arrived at a contradiction.
        So our initial assumption cannot be correct, i.e.
        <m>\Poly</m> cannot be finite-dimensional.
      </p>
    </proof>

    <example>
      <statement>
        <p>
          We will not prove this here,
          but the following vector spaces are also infinite-dimensional:

          <ul>
            <li>
              <p>
                <m>\mathbb{R}^\infty</m>,
              </p>
            </li>

            <li>
              <p>
                <m>\Fun(X)</m> where <m>X</m> is an infinite set,
              </p>
            </li>

            <li>
              <p>
                <m>\Cont(I)</m> for any nonempty interval <m>I</m>, and
              </p>
            </li>

            <li>
              <p>
                <m>\Diff(I)</m> for any open interval <m>I</m>.
              </p>
            </li>
          </ul>
        </p>
      </statement>
    </example>
  </introduction>

  <subsection xml:id="sifting_subsection">
    <title>Sifting</title>
    <p>
      If we consider the proof of <xref ref="bumping_off_lemma">Proposition</xref>
      (the <sq>Bumping off</sq> Proposition)
      carefully, we find that it makes use of a
      <em>sifting algorithm</em>.
      This algorithm can actually be applied to <em>any</em>
      list of vectors <m>\ve{v}_1, \ve{v}_2, \ldots, \ve{v}_n</m> in a vector space.
      Consider each vector <m>\ve{v}_i</m> in the list consecutively.
      If <m>\ve{v}_i</m> is the zero vector,
      or if it is a linear combination of the preceding vectors
      <m>\ve{v}_1, \ve{v}_2, \ldots, \ve{v}_{n-1}</m>, remove it from the list.
    </p>

    <example>
      <statement>
      <p>
        Sift the following list of vectors in <m>\mathbb{R}^3</m>:
        <md>
          <mrow>\ve{v}_1 \amp = (1,2,-1), \amp  \ve{v}_2 \amp = (0, 0, 0), \amp  \ve{v}_3 \amp = (3, 6, -3)</mrow>
          <mrow>\ve{v}_4 \amp = (1, 0, 5), \amp  \ve{v}_5 \amp = (5, 4, 13), \amp   \ve{v}_6 \amp = (1, 1, 0)</mrow>
        </md>.
      </p>

      <p>
        We start with <m>\ve{v}_1</m>.
        Since it is not the zero vector,
        and is not a linear combination of any preceding vectors,
        it remains.
        We move on to <m>\ve{v}_2</m>,
        which is zero, so we remove it.
        We move on to <m>\ve{v}_3</m>,
        which by inspection is equal to <m>3 \ve{v}_1</m>, so we remove it.
        We move on to <m>\ve{v}_4</m>.
        It is not zero,
        and cannot be expressed as a multiple of <m>\ve{v}_1</m>
        (check this),
        so it remains.
        We move on to <m>\ve{v}_5</m>.
        We check if it can be written as a linear combination
        <me>
          \ve{v}_5 = a\ve{v}_1 + b \ve{v}_4
        </me>
        and find the solution <m>a=2, b=3</m>
        (check this),
        so we remove it.
        Finally we move on to <m>\ve{v}_6</m>.
        We check if it can be written as a linear combination
        <me>
          \ve{v}_6 = a\ve{v}_1 + b \ve{v}_4
        </me>
        and find no solutions
        (check this),
        so it remains.
        Our final sifted list is
        <me>
          \ve{v}_1, \ve{v}_4, \ve{v}_6
        </me>.
      </p>

      

      </statement>
    </example>

    <exercise>
        <statement>
          <p>
            Do the three <sq>check this</sq> calculations above.
          </p>
        </statement>
      </exercise>

    <p>
      Sifting is a very useful way to construct a basis of a vector space!
    </p>

    <lemma xml:id="sift_lemma_basis">
      <statement>
        <p>
          If a list of vectors <m>\ve{v}_1, \ve{v}_2, \ldots, \ve{v}_n</m> spans a vector space <m>V</m>,
          then sifting the list will result in a basis for <m>V</m>.
        </p>
      </statement>
    </lemma>

    <proof>
      <p>
        At each step,
        the vector that is removed from the list is either the zero vector,
        or a linear combination of the vectors before it.
        So if we remove this vector, the resulting list will still span <m>V</m>.
        Thus by the end of the process,
        the final sifted list of vectors still spans <m>V</m>.
      </p>

      <p>
        To see that the final sifted list is linearly independent,
        we can apply <xref ref="lin_dependence_prop">Proposition</xref>.
        By construction,
        no vector in the final sifted list is a linear combination of the preceding vectors
        (if it was, it would have been removed!).
        Hence the final sifted list is not linearly dependent,
        so it must be linearly independent!
      </p>
    </proof>

    <corollary xml:id="first_corollary_please">
      <statement>
        <p>
          Any linearly independent list of vectors
          <m>\ve{v}_1, \ve{v}_2, \ldots, \ve{v}_k</m> in a finite-dimensional vector space <m>V</m> can be extended to a basis of <m>V</m>.
        </p>
      </statement>
    </corollary>

    <proof>
      <p>
        Since <m>V</m> is finite-dimensional,
        it has a basis <m>\ve{e}_1, \ldots, \ve{e}_n</m>.
        Now consider the list
        <me>
          L : \ve{v}_1, \ve{v}_2, \ldots, \ve{v}_k, \ve{e}_1, \ve{e}_2, \ldots, \ve{e}_n
        </me>
        which clearly spans <m>V</m>.
        By sifting this list, we will arrive at a basis for <m>V</m>,
        by <xref ref="sift_lemma_basis">Lemma</xref>.
        Some of the <m>\ve{e}</m>-vectors may have been removed.
        But none of the <m>\ve{v}</m>-vectors will have been removed,
        since that would mean some
        <m>\ve{v}_i</m> is a linear combination of the preceding vectors
        <m>\ve{v}_1, \ldots, \ve{v}_{i-1}</m>, which is impossible,
        as <m>\ve{v}_1, \ldots, \ve{v}_k</m> is linearly independent list.
        Hence after sifting the list <m>L</m> we indeed extend our original list
        <m>\ve{v}_1, \ldots, \ve{v}_k</m> to a basis of <m>V</m>.
      </p>
    </proof>

    <corollary xml:id="lin-ind-implies-basis">
      <statement>
        <p>
          If <m>\ve{v}_1, \ve{v}_2, \ldots, \ve{v}_n</m> is a linearly independent list of <m>n</m> vectors in an <m>n</m>-dimensional vector space <m>V</m>,
          then it is a basis.
        </p>
      </statement>
    </corollary>

    <proof>
      <p>
        By <xref ref="first_corollary_please">Corollary</xref>,
        we can extend <m>\ve{v}_1, \ve{v}_2, \ldots, \ve{v}_n</m> to a basis for <m>V</m>.
        But <m>V</m> has dimension <m>n</m>,
        so the basis must contain only <m>n</m> vectors by <xref ref="inv_dim">Theorem</xref> (Invariance of Dimension).
        So we have not added any vectors at all!
        Hence our original list was already a basis.
      </p>
    </proof>

    <example>
      <statement>
        <p>
          In <xref ref="new_basis_for_poly_3">Example</xref>
          we showed that the list of polynomials
          <me>
            \ve{q}_0 (x) := 1, \,\, \ve{q}_1 (x):= x, \,\, \ve{q}_2(x) := 2x^2 - 1, \,\, \ve{q}_3(x) := 4x^3 - 3x
          </me>
          is linearly independent in <m>\Poly_3</m>.
          Since <m>\Dim \Poly_3 = 4</m>,
          we see that it is a basis of <m>\Poly_3</m>.
        </p>

        <assemblage>
          <p>
            In <xref ref="chebyshev_example">Exercise</xref>,
            you showed that <m>\ve{q}_0, \ldots, \ve{q}_3</m> is a basis for <m>\Poly_3</m> by <sq>brute force</sq>.
            This new method is <em>different</em>!
          </p>
        </assemblage>

      </statement>
    </example>
  </subsection>

  <exercises>

<exercise xml:id="exercise_for_new_basis">
    <statement>
      <p>
        Sift the list of vectors
        <md>
          <mrow>\ve{v}_1 \amp = (0,0,0), \amp  \ve{v}_2 \amp = (1, 0, -1), \amp  \ve{v}_3 \amp = (1, 2, 3)</mrow>
          <mrow>\ve{v}_4 \amp = (3, 4, 5), \amp  \ve{v}_5 \amp = (4, 8, 12), \amp   \ve{v}_6 \amp = (1, 1, 0)</mrow>
        </md>.
      </p>
    </statement>
  </exercise>

  <exercise xml:id="true_false_span_lin_ind">
    <statement>
      <p>
        Let <m>V</m> be a vector space of dimension <m>n</m>.
        State whether each of the following statements is true or false.
        If it is true, prove it.
        If it is false, give a counterexample.

        <ul>
          <li>
            <title>(a)</title>
            <p>
              Any linearly independent list of vectors in <m>V</m> contains at most <m>n</m> vectors.
            </p>
          </li>

          <li>
            <title>(b)</title>
            <p>
              Any list of vectors which spans <m>V</m> contains at least <m>n</m> vectors.
            </p>
          </li>
        </ul>
      </p>
    </statement>
  </exercise>

  <exercise>
    <statement>
      <p>
        Let <m>\basis{B} = \left\{ \ve{v}_1, \ldots, \ve{v}_n \right\}</m> be a linearly independent list of vectors in a vector space <m>V</m>.
        Suppose that <m>\ve{v}</m> is a vector in <m>V</m> which cannot be written as a linear combination of the vectors from <m>\basis{B}</m>.
        Show that the list <m>\basis{B}' = \left\{ \ve{v}_1, \ldots, \ve{v}_n, \ve{v} \right\}</m> is still linearly independent.
        (Hint: Use the Linear Combination of Preceding Vectors Proposition.)
      </p>
    </statement>
  </exercise>

  <exercise xml:id="n_lin_ind_is_basis">
    <statement>
      <p>
        Complete the proof of the following lemma.
      </p>

      <p>
        <em>Lemma.</em> Suppose <m>V</m> is a vector space of dimension <m>n</m>.
        Then any linearly independent set of <m>n</m> vectors in <m>V</m> is a basis for <m>V</m>.
      </p>

      <p>
        <em>Proof.</em> Let <m>\basis{B} = \left\{ \ve{v}_1, \ldots, \ve{v}_n \right\}</m> be a linearly independent set of vectors in <m>V</m>.
      </p>

      <p>
        Suppose that <m>\basis{B}</m> is
        <em>not</em> a basis for <m>V</m>.
      </p>

      <p>
        Therefore, <m>\basis{B}</m> does not span <m>V</m>, since ... (a)
      </p>

      <p>
        Therefore, there exists <m>\ve{v} \in V</m> such that ... (b)
      </p>

      <p>
        Now, add <m>\ve{v}</m> to the list
        <m>\basis{B}</m> to obtain a new list <m>\basis{B}' :=</m> ... (c)
      </p>

      <p>
        The new list <m>\basis{B}'</m> is linearly independent because ... (d)
      </p>

      <p>
        This is a contradiction because ... (e)
      </p>

      <p>
        Hence, <m>\basis{B}</m> must be a basis for <m>V</m>.
      </p>
    </statement>
  </exercise>

  <exercise xml:id="checking_matrices_lin_dep">
    <statement>
      <p>
        Use <xref ref="true_false_span_lin_ind">Exercise</xref>(a) to show that the list of matrices in
        <m>\Mat_{2,2}</m> in <xref ref="x2_by_2_matrices_lin_dep">Exercise</xref> is linearly dependent.
      </p>
    </statement>
  </exercise>

  <exercise>
    <statement>
      <p>
        In each case,
        use the results in <xref ref="true_false_span_lin_ind">Exercises</xref>
        and <xref ref="n_lin_ind_is_basis"></xref>
        to determine if <m>\basis{B}</m> is a basis for <m>V</m>.

        <ul>
          <li>
            <title>(a)</title>
            <p>
              <m>V = \Poly_2</m>,
              <m>\basis{B} = \left\{ 2 + x^2, \, 1-x, \, 1 + x - 3x^2, \, x-x^2 \right\}</m>
            </p>
          </li>

          <li>
            <title>(b)</title>
            <p>
              <m>V = \Mat_{2,2}</m>,
              <me>\basis{B} = \left\{ 
 \begin{bmatrix}
1 &amp; 2 \\
-1 &amp; 3
\end{bmatrix},\,
 \begin{bmatrix}
0 &amp; 1\\
3 &amp; -1
\end{bmatrix},\,
\begin{bmatrix}
1 &amp; 2\\
3 &amp; 4
\end{bmatrix}
     \right\} </me>
            </p>
          </li>

          <li>
            <title>(c)</title>
            <p>
              <m>V = \Trig_2</m>,
              <m>\basis{B} = \left\{ \sin^2 x, \, \cos^2 x, \, 1 - \sin 2x, \, \cos 2x + 3 \sin 2x \right\}</m>
            </p>
          </li>
        </ul>
      </p>
    </statement>
  </exercise>

  <exercise>
    <statement>
      <p>
        Let <m>\left\{ \ve{u}, \ve{v}, \ve{w} \right\}</m> be a linearly independent list of vectors in a vector space <m>V</m>.
        State whether each of the following statements is true or false.
        If it is true, prove it.
        If it is false, give a counterexample.
        (Hint: Use the definition of linear independence.)

        <ul>
          <li>
            <title>(a)</title>
            <p>
              The list <m>\left\{ \ve{u} + \ve{v}, \, \ve{v} + \ve{w}, \, \ve{u} + \ve{w} \right\}</m> is linearly independent.
            </p>
          </li>

          <li>
            <title>(b)</title>
            <p>
              The list <m>\left\{ \ve{u} - \ve{v}, \, \ve{v} - \ve{w}, \, \ve{u} - \ve{w} \right\}</m> is linearly independent.
            </p>
          </li>
        </ul>
      </p>
    </statement>
  </exercise>

  <exercise xml:id="dim_poly_at_2_ex">
    <statement>
      <p>
        For each of the following,
        show that <m>V</m> is a subspace of <m>\Poly_2</m>,
        find a basis for <m>V</m>, and compute <m>\Dim V</m>.

        <ul>
          <li>
            <title>(a)</title>
            <p>
              <m>V = \{ p \in \Poly_2 : p(2) = 0 \}</m>
            </p>
          </li>

          <li>
            <title>(b)</title>
            <p>
              <m>V = \{ p \in \Poly_2 : xp'(x) = p(x) \}</m>
            </p>
          </li>
        </ul>
      </p>
    </statement>
  </exercise>

  </exercises>

</section>

